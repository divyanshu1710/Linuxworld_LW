{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3262e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.0 (SDL 2.28.0, Python 3.9.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import turtle\n",
    "import pygame\n",
    "\n",
    "# Initialize Pygame\n",
    "pygame.init()\n",
    "\n",
    "# Set up the turtle screen\n",
    "screen = turtle.Screen()\n",
    "screen.title(\"Welcome\")\n",
    "screen.bgcolor(\"black\")\n",
    "screen.setup(width=800, height=600)\n",
    "\n",
    "# Create the turtle\n",
    "pen = turtle.Turtle()\n",
    "pen.speed(1)\n",
    "pen.color(\"white\")\n",
    "pen.penup()\n",
    "pen.hideturtle()\n",
    "pen.goto(-200, 0)\n",
    "\n",
    "# Play the song\n",
    "pygame.mixer.music.load(\"01. Welcome.mp3\")\n",
    "pygame.mixer.music.play()\n",
    "\n",
    "# Define the text to display\n",
    "text = \"Welcome guys, this is Team Incognito\"\n",
    "\n",
    "# Draw the text\n",
    "for char in text:\n",
    "    pen.write(char, align=\"center\", font=(\"Arial\", 24, \"normal\"))\n",
    "    pen.forward(20)\n",
    "\n",
    "# Function to draw text\n",
    "def draw_text(text, x, y, size=20):\n",
    "    turtle.penup()\n",
    "    turtle.goto(x, y)\n",
    "    turtle.pendown()\n",
    "    turtle.write(text, align='center', font=('Arial', size, 'bold'))\n",
    "\n",
    "# Function to draw a circle\n",
    "def draw_circle(radius, color):\n",
    "    turtle.fillcolor(color)\n",
    "    turtle.begin_fill()\n",
    "    turtle.circle(radius)\n",
    "    turtle.end_fill()\n",
    "\n",
    "# Set up the turtle screen\n",
    "turtle.setup(400, 400)\n",
    "turtle.speed(2)\n",
    "\n",
    "# Draw the circle for the face\n",
    "draw_circle(100, 'yellow')\n",
    "\n",
    "# Draw the eyes\n",
    "turtle.penup()\n",
    "turtle.goto(-40, 120)\n",
    "turtle.pendown()\n",
    "draw_circle(10, 'black')\n",
    "\n",
    "turtle.penup()\n",
    "turtle.goto(40, 120)\n",
    "turtle.pendown()\n",
    "draw_circle(10, 'black')\n",
    "\n",
    "# Draw the mouth\n",
    "turtle.penup()\n",
    "turtle.goto(-40, 90)\n",
    "turtle.pendown()\n",
    "turtle.setheading(-60)\n",
    "turtle.circle(40, 120)\n",
    "\n",
    "# Draw the text\n",
    "draw_text(\"Hello\", 0, -120, 24)\n",
    "\n",
    "# Hide the turtle cursor\n",
    "turtle.hideturtle()\n",
    "\n",
    "# Keep the window open\n",
    "turtle.done()\n",
    "\n",
    "# Quit Pygame\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb72a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b5e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "import datetime\n",
    "import webbrowser\n",
    "import random\n",
    "import requests\n",
    "import json\n",
    "import pytz\n",
    "import speech_recognition as sr\n",
    "import matplotlib.pyplot as plt\n",
    "import pygame\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "print(\"\\t\\t\\t\\t\\tWelcome to team 23's assisstent\")\n",
    "print(\"\\t\\t\\t\\t\\t______________________________\")\n",
    "print(\"\\t\\t\\t\\t\\toption 1: get news\")\n",
    "print(\"\\t\\t\\t\\t\\toption 2: tell joke\")\n",
    "print(\"\\t\\t\\t\\t\\toption 3: get time\")\n",
    "print(\"\\t\\t\\t\\t\\toption 4: youtube\")\n",
    "print(\"\\t\\t\\t\\t\\toption 5: spotify\")\n",
    "print(\"\\t\\t\\t\\t\\toption 6: draw indian flag\")\n",
    "print(\"\\t\\t\\t\\t\\toption 7: titanic model\")\n",
    "print(\"\\t\\t\\t\\t\\toption 8: Volume Controller\")\n",
    "print(\"\\t\\t\\t\\t\\toption 9: Photo editor\")\n",
    "print(\"\\t\\t\\t\\t\\toption 10:Photo replace\")\n",
    "print(\"\\t\\t\\t\\t\\toption 11:cursor\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Initialize the speech recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Set up the voice assistant's greetings\n",
    "greetings = {\n",
    "    \"morning\": \"Good morning, Ayush!,How may i assist you\",\n",
    "    \"afternoon\": \"Good afternoon, Ayush!,How may i assist you\",\n",
    "    \"evening\": \"Good evening, Ayush!, How may i assist you\"\n",
    "}\n",
    "\n",
    "# Function to get the current time and determine the appropriate greeting\n",
    "def get_greeting():\n",
    "    current_time = datetime.datetime.now(pytz.timezone('Asia/Kolkata')).time()\n",
    "    if current_time.hour < 12:\n",
    "        return greetings[\"morning\"]\n",
    "    elif 12 <= current_time.hour < 18:\n",
    "        return greetings[\"afternoon\"]\n",
    "    else:\n",
    "        return greetings[\"evening\"]\n",
    "\n",
    "# Function to speak the given text\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to open a specific website\n",
    "def open_website(url):\n",
    "    webbrowser.open(url)\n",
    "\n",
    "# Function to fetch the latest news headlines\n",
    "def get_news():\n",
    "    api_key = \"YOUR_NEWS_API_KEY\"  # Replace with your own News API key\n",
    "    url = f\"https://newsapi.org/v2/top-headlines?country=us&apiKey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    data = json.loads(response.text)\n",
    "    if data[\"status\"] == \"ok\":\n",
    "        articles = data[\"articles\"]\n",
    "        for article in articles[:5]:\n",
    "            speak(article[\"title\"])\n",
    "            print(article[\"title\"])\n",
    "\n",
    "# Function to tell a joke\n",
    "def tell_joke():\n",
    "    jokes = [\n",
    "        \"Why don't scientists trust atoms? Because they make up everything!\",\n",
    "        \"Did you hear about the mathematician who's afraid of negative numbers? He will stop at nothing to avoid them!\",\n",
    "        \"Why don't skeletons fight each other? They don't have the guts!\",\n",
    "        \"Why don't eggs tell jokes? Because they might crack up!\",\n",
    "        \"Why did the scarecrow win an award? Because he was outstanding in his field!\"\n",
    "    ]\n",
    "    joke = random.choice(jokes)\n",
    "    speak(joke)\n",
    "    print(joke)\n",
    "\n",
    "# Function to get the current time and speak it\n",
    "def get_current_time():\n",
    "    current_time = datetime.datetime.now(pytz.timezone('Asia/Kolkata')).strftime(\"%I:%M %p\")\n",
    "    speak(f\"The current time is {current_time}\")\n",
    "    print(f\"The current time is {current_time}\")\n",
    "    \n",
    "def titanic():\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "    url = 'https://www.kaggle.com/datasets/yasserh/titanic-dataset'\n",
    "    df = pd.read_csv('train.csv')\n",
    "\n",
    "# Step 2: Data preprocessing\n",
    "# Drop irrelevant columns\n",
    "    df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin','Fare',\"Embarked\"], axis=1)\n",
    "\n",
    "# Fill missing values\n",
    "    df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
    "\n",
    "# Split features and target variable\n",
    "    X = df.drop('Survived', axis=1)\n",
    "    y = df['Survived']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Model training\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "#print(f\"Accuracy: {accuracy}\")\n",
    "    Pclass=int(input(\"Enter the Passenger class of the passenger: \\n\"))\n",
    "    gender=input(\"Enter the gender of the passenger M for male F for female: \\n\")\n",
    "    if gender==\"M\":\n",
    "        s=1\n",
    "    elif gender==\"F\":\n",
    "        s=0\n",
    "    else:\n",
    "        print(\"Enter valid gender cause LGBTQ is just a disease\")\n",
    "    age=float(input(\"Enter the age of passenger: \\n\"))\n",
    "    sib=int(input(\"Enter sibling count: \\n\"))\n",
    "    pc=int(input(\"Enter the number of children of the passenger: \\n\"))\n",
    "    sur=model.predict([[Pclass,s,age,sib,pc]])\n",
    "    if sur[0]==1:\n",
    "        print(\"The passenger survived\")\n",
    "    else:\n",
    "        print(\"The passenger died\")\n",
    "        \n",
    "\n",
    "    \n",
    "def draw_indian_flag():\n",
    "    # Dimensions of the flag\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as py\n",
    "    import matplotlib.patches as patch\n",
    "#Plotting the tri colours in national flag\n",
    "    a = patch.Rectangle((0,1), width=12, height=2, facecolor='green', edgecolor='grey')\n",
    "    b = patch.Rectangle((0,3), width=12, height=2, facecolor='white', edgecolor='grey')\n",
    "    c = patch.Rectangle((0,5), width=12, height=2, facecolor='#FF9933', edgecolor='grey')\n",
    "    m,n = py.subplots()\n",
    "    n.add_patch(a)\n",
    "    n.add_patch(b)\n",
    "    n.add_patch(c)\n",
    "#AshokChakra Circle\n",
    "    radius=0.8\n",
    "    py.plot(6,4, marker = 'o', markerfacecolor = '#000088ff', markersize = 9.5)\n",
    "    chakra = py.Circle((6, 4), radius, color='#000088ff', fill=False, linewidth=7)\n",
    "    n.add_artist(chakra)\n",
    "#24 spokes in AshokChakra\n",
    "    for i in range(0,24):\n",
    "       p = 6 + radius/2 * np.cos(np.pi*i/12 + np.pi/48)\n",
    "       q = 6 + radius/2 * np.cos(np.pi*i/12 - np.pi/48)\n",
    "       r = 4 + radius/2 * np.sin(np.pi*i/12 + np.pi/48)\n",
    "       s = 4 + radius/2 * np.sin(np.pi*i/12 - np.pi/48)\n",
    "       t = 6 + radius * np.cos(np.pi*i/12)\n",
    "       u = 4 + radius * np.sin(np.pi*i/12)\n",
    "       n.add_patch(patch.Polygon([[6,4], [p,r], [t,u],[q,s]], fill=True, closed=True, color='#000088ff'))\n",
    "    py.axis('equal')\n",
    "    py.show()\n",
    "    \n",
    "\n",
    "    # Load and play the national anthem\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load('national_anthem.mp3')\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "    # Wait for the anthem to finish playing\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        continue\n",
    "        \n",
    "def volume():\n",
    "    import cv2      #library for image\n",
    "    import mediapipe as mp  #tasks like hand tracking, pose estimation, object detection, and more. \n",
    "    from math import hypot  #hypot - returns the Euclidean norm (distance from the origin to the coordinates given)\n",
    "    from ctypes import cast, POINTER    #enable you to define the necessary data types, call functions from shared libraries, pass data between Python and C, and handle error conditions.\n",
    "    from comtypes import CLSCTX_ALL     \n",
    "    from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "    import numpy as np\n",
    "    \n",
    "\n",
    "\n",
    "#connect to the default camera\n",
    "    cap = cv2.VideoCapture(0)   \n",
    "\n",
    "\n",
    "#initialize mediapipe hands\n",
    "    mp_Hands = mp.solutions.hands   #detect the landmarks of the hands in an image\n",
    "    hands = mp_Hands.Hands()\n",
    "    mp_Draw = mp.solutions.drawing_utils\n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    from math import hypot\n",
    "    from ctypes import cast, POINTER\n",
    "    from comtypes import CLSCTX_ALL\n",
    "    from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "    import numpy as np\n",
    "    import pygame\n",
    "    \n",
    "    # Initialize Pygame mixer for audio playback\n",
    "    pygame.mixer.init()\n",
    "    \n",
    "    # Connect to the default camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Initialize mediapipe hands\n",
    "    mp_Hands = mp.solutions.hands\n",
    "    hands = mp_Hands.Hands()\n",
    "    mp_Draw = mp.solutions.drawing_utils\n",
    "    \n",
    "    # Accessing the speakers using pycaw\n",
    "    devices = AudioUtilities.GetSpeakers()\n",
    "    interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "    volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "    \n",
    "# Find the volume range between the minimum and maximum volume\n",
    "    volMin, volMax = volume.GetVolumeRange()[:2]\n",
    "\n",
    "# Create a Pygame mixer channel for music playback\n",
    "    music_channel = pygame.mixer.Channel(0)\n",
    "\n",
    "# Capturing an image from the camera\n",
    "    while True:\n",
    "        status, image = cap.read()\n",
    "        imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(imageRGB)\n",
    "\n",
    "        lmlist = []\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for handlandmark in results.multi_hand_landmarks:\n",
    "                for id, lm in enumerate(handlandmark.landmark):\n",
    "                    h, w, c = image.shape\n",
    "                    cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                    lmlist.append([id, cx, cy])\n",
    "                mp_Draw.draw_landmarks(image, handlandmark, mp_Hands.HAND_CONNECTIONS)\n",
    "\n",
    "        if lmlist != []:\n",
    "            x1, y1 = lmlist[4][1], lmlist[4][2]\n",
    "            x2, y2 = lmlist[8][1], lmlist[8][2]\n",
    "\n",
    "            cv2.circle(image, (x1, y1), 15, (255, 0, 0), cv2.FILLED)\n",
    "            cv2.circle(image, (x2, y2), 15, (255, 0, 0), cv2.FILLED)\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "\n",
    "            length = hypot(x2 - x1, y2 - y1)\n",
    "            vol = np.interp(length, [15, 220], [volMin, volMax])\n",
    "\n",
    "            volume.SetMasterVolumeLevel(vol, None)\n",
    "\n",
    "        # Play/pause music when hand distance crosses a threshold\n",
    "            if length < 50:\n",
    "                if pygame.mixer.music.get_busy():\n",
    "                    pygame.mixer.music.pause()\n",
    "                else:\n",
    "                    pygame.mixer.music.unpause()\n",
    "\n",
    "        cv2.imshow('Image', image)\n",
    "        if cv2.waitKey(1) == 27:  # Press ESC to exit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def Editor():\n",
    "    def adjust_brightness(image, value):\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(hsv)\n",
    "\n",
    "        # Adjust the brightness by adding the specified value to the V channel\n",
    "        v = cv2.add(v, value)\n",
    "        v = np.clip(v, 0, 255)\n",
    "\n",
    "        hsv = cv2.merge((h, s, v))\n",
    "        adjusted_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        return adjusted_image\n",
    "\n",
    "    def adjust_sharpness(image, factor):\n",
    "        blurred = cv2.GaussianBlur(image, (0, 0), sigmaX=2)\n",
    "        sharpened = cv2.addWeighted(image, 1.0 + factor, blurred, -factor, 0)\n",
    "        return sharpened\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread('image_6487327.jpg')\n",
    "\n",
    "    # Adjust brightness by adding 50 (positive values increase brightness, negative decrease)\n",
    "    brightened_image = adjust_brightness(image, 50)\n",
    "\n",
    "    # Adjust sharpness by multiplying by a factor of 1.5 (values > 1 increase sharpness, < 1 decrease)\n",
    "    sharpened_image = adjust_sharpness(brightened_image, 1.5)\n",
    "\n",
    "    # Display the original, adjusted brightness, and sharpened images\n",
    "    cv2.imshow('Original', image)\n",
    "    cv2.imshow('Brightness Adjusted', brightened_image)\n",
    "    cv2.imshow('Sharpened', sharpened_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def pose():\n",
    "    # Initialize pygame\n",
    "    pygame.init()\n",
    "\n",
    "# Set the window size and title\n",
    "    pygame.display.set_mode((800, 600))\n",
    "    pygame.display.set_caption(\"SET YOUR HAIR\")\n",
    "\n",
    "# Load the song\n",
    "    song_path = r\"C:\\Users\\HP\\Desktop\\training\\Tujhe Dekha Toh Yeh Jaana Sanam ! Instrumental.mp3\"\n",
    "    pygame.mixer.music.load(song_path)\n",
    "\n",
    "# Initialize the hand detector\n",
    "    detector = HandDetector(detectionCon=0.8)\n",
    "\n",
    "# Shahrukh Khan's iconic pose landmarks (wrist, elbow, and shoulder)\n",
    "    pose_landmarks = [4, 5, 6]\n",
    "\n",
    "# Main loop\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "    # Read the frame from the camera\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "    # Detect hands in the frame\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        hands, _ = detector.findHands(frame)\n",
    "\n",
    "        if hands:\n",
    "            hand = hands[0]\n",
    "            landmarks = hand[\"lmList\"]\n",
    "            fingers = detector.fingersUp(hand)\n",
    "\n",
    "        # Check if the hand is in Shahrukh Khan's iconic pose\n",
    "            if all(landmarks[i][2] > landmarks[i + 1][2] for i in pose_landmarks) and all(fingers):\n",
    "            # Play the song\n",
    "                pygame.mixer.music.play()\n",
    "\n",
    "            # Display a message on the frame\n",
    "                cvzone.cornerRect(frame, (20, 20, 180, 80), 20, rt=0)\n",
    "                cv2.putText(frame, \"Set your hair\", (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Show the frame\n",
    "        cv2.imshow(\"Shahrukh Khan Iconic Pose Detection\", frame)\n",
    "\n",
    "    # Check for key press events\n",
    "        if cv2.waitKey(1) == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def photoswap():\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load Messi's face image\n",
    "    messi_face = cv2.imread('messi1.jpg')\n",
    "\n",
    "# Check if the Messi's face image is loaded successfully\n",
    "    if messi_face is None:\n",
    "        print(\"Failed to load Messi's face image.\")\n",
    "        exit()\n",
    "\n",
    "# Open a video capture object\n",
    "    cap = cv2.VideoCapture(0)  # Change 0 to the appropriate camera index if necessary\n",
    "\n",
    "# Check if the video capture is successfully opened\n",
    "    if not cap.isOpened():\n",
    "        print(\"Failed to open video capture.\")\n",
    "        exit()\n",
    "\n",
    "# Get the video's width and height for the output\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    output_video = cv2.VideoWriter('face_swapped_video.mp4', fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "# Start capturing and processing frames\n",
    "    \n",
    "    # Read a frame from the video capture\n",
    "    while True:\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Failed to capture frame.\")\n",
    "            break\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Perform face swapping\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Resize Messi's face image to match the size of the detected face\n",
    "            messi_face_resized = cv2.resize(messi_face, (w, h))\n",
    "\n",
    "        # Replace the face region in the original frame with Messi's face\n",
    "        frame[y:y+h, x:x+w] = messi_face_resized\n",
    "\n",
    "    # Write the modified frame to the output video\n",
    "        output_video.write(frame)\n",
    "\n",
    "    # Display the resulting frame\n",
    "        cv2.imshow('Face Swapped Video', frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the video capture and video writer objects\n",
    "    cap.release()\n",
    "    output_video.release()\n",
    "\n",
    "# Destroy any remaining windows\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def cursor():\n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    import pyautogui\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    hand_detector= mp.solutions.hands.Hands()\n",
    "    drawing_utils  = mp.solutions.drawing_utils\n",
    "    screen_width, screen_height = pyautogui.size()\n",
    "    index_y = 0\n",
    "\n",
    "    while True:\n",
    "        _, frame=cap.read()\n",
    "        frame = cv2.flip(frame,1)\n",
    "        frame_height, frame_width, _ =frame.shape\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        output = hand_detector.process(rgb_frame)\n",
    "        hands = output.multi_hand_landmarks\n",
    "        if hands:\n",
    "            for hand in hands:\n",
    "                drawing_utils.draw_landmarks(frame, hand)\n",
    "                landmarks=hand.landmark\n",
    "                for id, landmark in enumerate(landmarks):   \n",
    "                    x = int(landmark.x * frame_width)\n",
    "                    y = int(landmark.y * frame_height)\n",
    "\n",
    "                    if id == 8:\n",
    "                        cv2.circle(img=frame, center=(x, y), radius=10, color=(0, 255, 255))\n",
    "                        index_x = screen_width/frame_width*x\n",
    "                        index_y = screen_height/frame_height*y\n",
    "\n",
    "                    if id == 4:\n",
    "                        cv2.circle(img=frame, center=(x, y), radius=10, color=(0, 255, 255))\n",
    "                        thumb_x = screen_width/frame_width*x\n",
    "                        thumb_y = screen_height/frame_height*y\n",
    "                        print('outside', abs(index_y-thumb_y))\n",
    "                        if abs(index_y-thumb_y) < 20:\n",
    "                            pyautogui.click()\n",
    "                            pyautogui.sleep(1)\n",
    "                        elif abs(index_y-thumb_y) < 100:\n",
    "                            pyautogui.moveTo(index_x, index_y)\n",
    "        cv2.imshow('Hand Mouse', frame)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "# Greet Ayush based on the time zone\n",
    "greeting = get_greeting()\n",
    "speak(greeting)\n",
    "print(greeting)\n",
    "\n",
    "# Main loop for voice assistant commands\n",
    "# Main loop for voice assistant commands\n",
    "while True:\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    try:\n",
    "        command = recognizer.recognize_google(audio).lower()\n",
    "        print(\"Command:\", command)\n",
    "\n",
    "        if \"youtube\" in command:\n",
    "            speak(\"Opening YouTube...\")\n",
    "            open_website(\"https://www.youtube.com\")\n",
    "            break\n",
    "\n",
    "        elif \"spotify\" in command:\n",
    "            speak(\"Opening Spotify...\")\n",
    "            open_website(\"https://www.spotify.com\")\n",
    "            break\n",
    "\n",
    "        elif \"news\" in command:\n",
    "            speak(\"Sure, here are some headlines...\")\n",
    "            open_website(\"https://www.ndtv.com\")\n",
    "            break\n",
    "\n",
    "        elif \"joke\" in command:\n",
    "            tell_joke()\n",
    "            break\n",
    "\n",
    "        elif \"time\" in command:\n",
    "            get_current_time()\n",
    "            break\n",
    "         \n",
    "        elif \"flag\" in command:\n",
    "            draw_indian_flag()\n",
    "            break\n",
    "\n",
    "        elif \"bye\" in command:\n",
    "            speak(\"Goodbye!\")\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "       \n",
    "        elif \"titanic\" in command:\n",
    "            titanic()\n",
    "            break\n",
    "            \n",
    "        elif \"volume\" in command:\n",
    "            volume()\n",
    "            break\n",
    "        \n",
    "        elif \"editor\" in command:\n",
    "            Editor()\n",
    "            break\n",
    "            \n",
    "        elif \"pose\" in command:\n",
    "            pose()\n",
    "            break\n",
    "            \n",
    "        elif \"swap\" in command:\n",
    "            photoswap()\n",
    "            break\n",
    "        \n",
    "        elif \"cursor\" in command:\n",
    "            cursor()\n",
    "            break\n",
    "            \n",
    "\n",
    "        else:\n",
    "            speak(\"Sorry, I didn't understand that command. Please try again.\")\n",
    "            print(\"Sorry, I didn't understand that command. Please try again.\")\n",
    "\n",
    "    except sr.UnknownValueError:\n",
    "        speak(\"Sorry, I couldn't understand your command. Please try again.\")\n",
    "        print(\"Sorry, I couldn't understand your command. Please try again.\")\n",
    "\n",
    "    except sr.RequestError:\n",
    "        speak(\"Sorry, there was an issue with the speech recognition service. Please try again.\")\n",
    "        print(\"Sorry, there was an issue with the speech recognition service. Please try again.\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d927c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.0 (SDL 2.28.0, Python 3.9.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pygame\n",
    "\n",
    "# Load the pre-trained face detection model (you may need to install it)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load Messi's face image\n",
    "messi_face = cv2.imread('messi1.jpeg')\n",
    "\n",
    "# Check if the Messi's face image is loaded successfully\n",
    "if messi_face is None:\n",
    "    print(\"Failed to load Messi's face image.\")\n",
    "    exit()\n",
    "\n",
    "# Open a video capture object\n",
    "cap = cv2.VideoCapture(0)  # Change 0 to the appropriate camera index if necessary\n",
    "\n",
    "# Check if the video capture is successfully opened\n",
    "if not cap.isOpened():\n",
    "    print(\"Failed to open video capture.\")\n",
    "    exit()\n",
    "\n",
    "# Get the video's width and height for the output\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_video = cv2.VideoWriter('face_swapped_video.mp4', fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "# Start capturing and processing frames\n",
    "while True:\n",
    "    # Read a frame from the video capture\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Perform face swapping\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Resize Messi's face image to match the size of the detected face\n",
    "        messi_face_resized = cv2.resize(messi_face, (w, h))\n",
    "\n",
    "        # Replace the face region in the original frame with Messi's face\n",
    "        frame[y:y+h, x:x+w] = messi_face_resized\n",
    "\n",
    "    # Write the modified frame to the output video\n",
    "    output_video.write(frame)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Face Swapped Video', frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load('AnkaraMessi.mp3')\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "    # Wait for the anthem to finish playing\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        continue\n",
    "# Release the video capture and video writer objects\n",
    "cap.release()\n",
    "output_video.release()\n",
    "\n",
    "\n",
    "\n",
    "# Destroy any remaining windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8009ff39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91800\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91800\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\distributions\\distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From C:\\Users\\91800\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\distributions\\bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "outside 752.5\n",
      "outside 57.5\n",
      "outside 5.0\n",
      "outside 152.5\n",
      "outside 137.5\n",
      "outside 102.5\n",
      "outside 100.0\n",
      "outside 97.5\n",
      "outside 152.5\n",
      "outside 107.5\n",
      "outside 270.0\n",
      "outside 90.0\n",
      "outside 55.0\n",
      "outside 75.0\n",
      "outside 37.5\n",
      "outside 5.0\n",
      "outside 40.0\n",
      "outside 5.0\n",
      "outside 30.0\n",
      "outside 20.0\n",
      "outside 10.0\n",
      "outside 10.0\n",
      "outside 27.5\n",
      "outside 12.5\n",
      "outside 12.5\n",
      "outside 15.0\n",
      "outside 2.5\n",
      "outside 82.5\n",
      "outside 7.5\n",
      "outside 15.0\n",
      "outside 32.5\n",
      "outside 35.0\n",
      "outside 47.5\n",
      "outside 37.5\n",
      "outside 42.5\n",
      "outside 27.5\n",
      "outside 32.5\n",
      "outside 17.5\n",
      "outside 40.0\n",
      "outside 27.5\n",
      "outside 5.0\n",
      "outside 7.5\n",
      "outside 15.0\n",
      "outside 47.5\n",
      "outside 32.5\n",
      "outside 27.5\n",
      "outside 32.5\n",
      "outside 27.5\n",
      "outside 32.5\n",
      "outside 20.0\n",
      "outside 17.5\n",
      "outside 50.0\n",
      "outside 5.0\n",
      "outside 37.5\n",
      "outside 50.0\n",
      "outside 25.0\n",
      "outside 7.5\n",
      "outside 5.0\n",
      "outside 42.5\n",
      "outside 55.0\n",
      "outside 35.0\n",
      "outside 25.0\n",
      "outside 22.5\n",
      "outside 17.5\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "hand_detector= mp.solutions.hands.Hands()\n",
    "drawing_utils  = mp.solutions.drawing_utils\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "index_y = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    _, frame=cap.read()\n",
    "    frame = cv2.flip(frame,1)\n",
    "    frame_height, frame_width, _ =frame.shape\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = hand_detector.process(rgb_frame)\n",
    "    hands = output.multi_hand_landmarks\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            drawing_utils.draw_landmarks(frame, hand)\n",
    "            landmarks=hand.landmark\n",
    "            for id, landmark in enumerate(landmarks):   \n",
    "                x = int(landmark.x * frame_width)\n",
    "                y = int(landmark.y * frame_height)\n",
    "\n",
    "                if id == 8:\n",
    "                    cv2.circle(img=frame, center=(x, y), radius=10, color=(0, 255, 255))\n",
    "                    index_x = screen_width/frame_width*x\n",
    "                    index_y = screen_height/frame_height*y\n",
    "\n",
    "                if id == 4:\n",
    "                    cv2.circle(img=frame, center=(x, y), radius=10, color=(0, 255, 255))\n",
    "                    thumb_x = screen_width/frame_width*x\n",
    "                    thumb_y = screen_height/frame_height*y\n",
    "                    print('outside', abs(index_y-thumb_y))\n",
    "                    if abs(index_y-thumb_y) < 20:\n",
    "                         pyautogui.click()\n",
    "                         pyautogui.sleep(1)\n",
    "                    elif abs(index_y-thumb_y) < 100:\n",
    "                        pyautogui.moveTo(index_x, index_y)\n",
    "    cv2.imshow('Hand Mouse', frame)\n",
    "    cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e80d2cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9296e22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
